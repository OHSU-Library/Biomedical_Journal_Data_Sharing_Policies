---
title: "Data Sharing Policies - Analysis"
author: "Analysis by Jessica Minnier, OHSU; github:jminnier"
date: \today
output:
  html_document:
    keep_md: yes
    theme: cerulean
    toc: yes
params:
  showcode: FALSE
---

```{r setup, include=FALSE}
list.of.packages <- c("broom","devtools","dplyr","ggplot2",
                      "tibble","tidyr","reshape2","stringr","knitr","pander","readxl")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
# install.packages(list.of.packages) # run this if some packages are too old and cause errors
# from http://stackoverflow.com/questions/4090169/elegant-way-to-check-for-missing-packages-and-install-them

library(dplyr)
library(ggplot2)
library(tidyr)
library(reshape2)
library(stringr)
library(knitr)
library(pander)
library(readxl)

knitr::opts_chunk$set(echo = params$showcode,
                      warning = FALSE,message = FALSE,tidy=TRUE)
```

# Data Processing

Here we read in the data and do some name and format manipulation.

```{r data}
# read journal data
exceldat <- read_excel("../Data-Sharing-Policies_2016-08-05.xlsx", sheet = "Data",
                    na = "N/A")
jdata <- exceldat[-1,] # remove line of info
jdata <- jdata[-which(is.na(jdata$Journal)),] # remove NAs

# add labels for DSM
dsm_labels = c(
  "Required as condition of publication, barring exceptions",
  "Required but no explicit statement regarding effect on publication/editorial decisions",
  "Explicitly encouraged/addressed, but not required.",
  "Mentioned indirectly",
  "Only protein, proteomic, and/or genomic data sharing are addressed.",
  "No mention"
)

# easier shorter names
jdata <- jdata%>%mutate(
  citable_2013 = `2013 Citable Publications`,
  citable_2014 = `2014 Citable Publications`,
  dsm=as.numeric(`Data Sharing Mark`), 
  dsm_fac = factor(dsm,levels = 1:6,
                   labels=dsm_labels),
  dsm2 = 1*(dsm<3),
  dsm2_fac = factor(dsm2,levels=0:1,
                    labels=c("Not Required","Required")),
  dsm2_fac_flip = factor(dsm2,levels=c(1,0), # reverse levels for for plotting only
                    labels=c("Required","Not Required")),
  oam=as.numeric(`Open Access Mark`),
  oam_fac = factor(oam,levels=0:1,
                   labels=c("Subscription","Open Access")),
  if_2013=`2013 Impact Factor`,
  if_2014=`2014 Impact Factor`,
  total_cites_2013 = `2013 Total Cites`,
  total_cites_2014 = `2014 Total Cites`)

# create long data for plotting and dplyr
jdata_if_long  <- jdata%>%select(Journal,dsm:if_2014)%>%
  rename(`2013`=if_2013,`2014`=if_2014)%>%
  gather(year,impact_factor,`2013`:`2014`)
jdata_tc_long <- jdata%>%select(Journal,contains("total_cites"))%>%
  rename(`2013`=total_cites_2013,`2014`=total_cites_2014)%>%
  gather(year,total_cites,`2013`:`2014`)
jdata_cit_long <- jdata%>%select(Journal,contains("citable_"))%>%
  rename(`2013`=citable_2013,`2014`=citable_2014)%>%
  gather(year,citable_items,`2013`:`2014`)

jdata_long = left_join(jdata_if_long,jdata_tc_long)
jdata_long = left_join(jdata_long,jdata_cit_long)
```

# Data Summaries and Distributions

We have data from `r nrow(jdata)` journals, including impact factor (IF) and total number of citations in years 2013 and 2014.

Data Sharing Mark (DSM) has 6 categories, and we create a collapsed DSM variable that has two categories for "required" (DSM = 1 or 2) and "not required" (DSM = 3, 4, 5 or 6).

The labels for Data Sharing Mark (DSM) are as follows:

```{r dsmlabel}
kable(tibble("DSM Numeric Value"=1:6,"DSM Description Label"=dsm_labels))
```

### Summary of Continuous Data
```{r}
tmps = summary(jdata%>%select(if_2013,if_2014,
                              citable_2013,citable_2014,
                              total_cites_2013,total_cites_2014))
kable(tmps)
```

### Summary of Categorical Data
```{r}
jdata%>%group_by(dsm_fac)%>%summarize("N"=n())%>%rename("DSM"=dsm_fac)%>%kable
jdata%>%group_by(oam_fac)%>%summarize("N"=n())%>%rename("Open Access"=oam_fac)%>%kable
```

### Table of DSM by Open Access

Open Access Mark (OAM) has two categories, Subscription and Open Access.

```{r}
with(jdata,table(dsm_fac,oam_fac))%>%kable()
```

### Table of 2 category DSM by Open Access

```{r}
with(jdata,table(dsm2_fac,oam_fac))%>%kable()
```

First we must determine whether IF or some transformation of IF is normally distributed. We can visually assess this by plotting histograms and density plots.

```{r density_if}

# check normality

ggplot(jdata_long,aes(impact_factor,fill=year))+geom_density(alpha=0.4)+
  theme_minimal()+xlab("Impact Factor")+ggtitle("Density of IF by Year")

ggplot(jdata_long,aes(impact_factor,fill=year))+geom_histogram(alpha=0.4,bins=40)+
  theme_minimal()+xlab("Impact Factor")+ggtitle("Histogram of IF by Year")

# check normality of log
ggplot(jdata_long,aes(log(impact_factor),fill=year))+geom_density(alpha=0.4)+
  theme_minimal()+xlab("log(IF)")+ggtitle("Density of log(IF) by Year")
ggplot(jdata_long,aes(log(impact_factor),fill=year))+geom_histogram(alpha=0.4,bins=40)+
  theme_minimal()+xlab("Impact Factor")+ggtitle("Histogram of log(IF) by Year")

```

We can also test the Normality assumption with the Shapiro Wilk's Test. We can test IF by year, as well as log(IF). We can also test within each DSM group since the main assumption for ANOVA is that the outcome (IF) is normal within each group.

```{r shapirowilk}
norm_test1 = data.frame("Y"=c("IF 2013","IF 2014","log(IF) 2013","log(IF) 2014"),
           rbind(broom::tidy(shapiro.test(jdata$if_2013)),
                 broom::tidy(shapiro.test(jdata$if_2014)),
                 broom::tidy(shapiro.test(log(jdata$if_2013))),
                 broom::tidy(shapiro.test(log(jdata$if_2014)))
           ))
norm_test1$p.value = as.character(signif(norm_test1$p.value,2))
kable(norm_test1,digits=4,caption = "Shapiro Wilk Normality Test p-values of IF")

# check normality within dsm groups
norm_test = jdata%>%group_by(dsm_fac)%>%summarize(
  "if_2013.pvalue"=shapiro.test(if_2013)$p.value,
  "if_2014.pvalue"=shapiro.test(if_2014)$p.value,                                "log_if_2013.pvalue"=shapiro.test(log(if_2013))$p.value,
  "log_if_2014.pvalue"=shapiro.test(log(if_2014))$p.value
)
norm_test[,-1] = apply(norm_test[,-1] ,2,function(k) as.character(signif(k,2)))

kable(norm_test,digits=4,
      caption = "Shapiro Wilk Normality Test p-values of IF within DSM Groups")
```

The p-values from the Shapiro Wilk's test are mostly very significant (hence we reject the normality assumption) and in general Impact Factor appears to be quite skewed so **nonparametric tests** (Wilcoxon, Kruskal-Wallis) will be more appropriate. Taking the log helps somewhat but does not solve the problem. Furthermore log-IF is much less intepretable. **Hence, we use nonparametric tests to compare distributions.**

# Impact Factor vs. Data Sharing Mark

We wish to assess how Impact Factor differs between journals with different data sharing types.

## Summarize Impact Factor Within Groups

We can describe the minimum, maximum, mean, and median of Impact factor as well as total citations for each DSM type.

```{r impact_factor_dsm_table}
tmpsum = jdata_long%>%group_by(dsm_fac,year)%>%summarize(
  "Number of Journals"=n(),
  "min_IF"=min(impact_factor,na.rm=T),
  "mean_IF"=mean(impact_factor,na.rm=T),
  "median_IF"=median(impact_factor,na.rm=T),
  "max_IF"=max(impact_factor,na.rm=T),
  "min_TotalCites"=min(total_cites,na.rm=T),
  "mean_TotalCites"=mean(total_cites,na.rm=T),
  "median_TotalCites"=median(total_cites,na.rm=T),
  "max_TotalCites"=max(total_cites,na.rm=T)
)
tmpsum = tmpsum%>%rename(DSM=dsm_fac)
kable(tmpsum,digits=2)
```

We can also visualize the distribution with a boxplot of IF by DSM type.

*Boxplot description*: The lower and upper "hinges" correspond to the first and third quartiles (the 25th and 75th percentiles). The upper whisker extends from the hinge to the highest value that is within 1.5 * IQR of the hinge, where IQR is the inter-quartile range, or distance between the first and third quartiles. The lower whisker extends from the hinge to the lowest value within 1.5 * IQR of the hinge. Data beyond the end of the whiskers are outliers and plotted as points (as specified by Tukey). (from `geom_boxplot` help page in the R `ggplot2` package.)

```{r boxplot_if_dsm,fig.width=9,fig.height=7}
ggplot(jdata_long,aes(x=dsm,y=impact_factor,fill=dsm_fac,alpha=year))+
  geom_boxplot()+theme_minimal()+
  scale_alpha_manual(values=c(0.3,0.7))+
  guides(alpha="none",fill=guide_legend(title="Data Sharing Mark",ncol=1))+
  xlab("Data Sharing Mark (1-6), Year (2013 light, 2014 dark)")+
  ylab("Impact Factor")+
  ggtitle("Boxplot of IF by DSM")+
  theme(legend.position="bottom")
```

Collapsing DSM into two categories:

```{r impact_factor_dsm_2cat_table}
tmpsum = jdata_long%>%group_by(dsm2_fac,year)%>%summarize(
  "Number of Journals"=n(),
  "min_IF"=min(impact_factor,na.rm=T),
  "mean_IF"=mean(impact_factor,na.rm=T),
  "median_IF"=median(impact_factor,na.rm=T),
  "max_IF"=max(impact_factor,na.rm=T),
  "min_TotalCites"=min(total_cites,na.rm=T),
  "mean_TotalCites"=mean(total_cites,na.rm=T),
  "median_TotalCites"=median(total_cites,na.rm=T),
  "max_TotalCites"=max(total_cites,na.rm=T)
)
tmpsum = tmpsum%>%rename(DSM=dsm2_fac)
kable(tmpsum,digits=2)
```

```{r boxplot_if_dsm_2cat,fig.width=9,fig.height=5}
ggplot(jdata_long,aes(x=dsm2_fac_flip,y=impact_factor,fill=dsm2_fac_flip,alpha=year))+
  geom_boxplot()+theme_minimal()+
  scale_alpha_manual(values=c(0.3,0.7))+
  guides(alpha="none",fill=guide_legend(title="Data Sharing"))+
  xlab("Data Sharing Required (No, Yes), Year (2013 light, 2014 dark)")+
  ggtitle("Boxplot of IF by Data Sharing Requirement")+
  ylab("Impact Factor")
```

## Analysis

We performed a nonparametric Kruskal-Wallis one way analysis of variance (ANOVA) of IF in 2013 and 2014 with DSM as a grouping factor to test for the association of IF with DSM. The Kruskal-Wallis test is a nonparametric version of ANOVA that tests whether the distribution of IF varies between DSM groups. We then perform post-hoc pairwise two-sample Wilcoxon (aka Mann-Whitney) tests to determine whether the median IF for journals differ between two DSM categories. The pairwise Wilcoxon tests corrects for multiple comparisons with the Holm procedure.

Note: The Wilcoxon test is testing the difference in medians between two groups when the distributions of the outcome (IF in this case) are the same. Based on the boxplots and densities the distributions do look similar within DSM group so we are comfortable making inferences on the medians.

```{r if_kruskal}
k_if13 = with(jdata,kruskal.test(if_2013~dsm))
k_if14 = with(jdata,kruskal.test(if_2014~dsm))
w_if13 = with(jdata,pairwise.wilcox.test(if_2013,dsm))
w_if14 = with(jdata,pairwise.wilcox.test(if_2014,dsm))
```

```{r if_kruskal_res}
#kw results
kw_results = data.frame(Y=c("if_2013","if_2014"),rbind(
  broom::tidy(k_if13),broom::tidy(k_if14)))
kw_results$p.value = as.character(signif(kw_results$p.value,2))
kw_results = kw_results%>%rename("degrees of freedom"=parameter)
kable(kw_results,digits=2)

#pairwise results
b1 = broom::tidy(w_if13)%>%mutate(p.value=as.character(signif(p.value,2)))%>%
  rename(if_2013.pvalue=p.value)
b2 = broom::tidy(w_if14)%>%mutate(p.value=as.character(signif(p.value,2)))%>%
  rename(if_2014.pvalue=p.value)
wilcox_if = left_join(b1,b2)
colnames(wilcox_if)  = c("DSM Group 1", "DSM Group 2", "IF 2013 p-value", "IF 2014 p-value")
```

The pairwise Wilcoxon test p-values are below (by DSM group number) for 2013 and 2014.
The p-values are adjusted for multiple comparisons with the `r w_if13$p.adjust.method` method.

Pairwise Wilcoxon p-values for IF 2013:
```{r wilcoxon_res_2013,  results='asis'}
signif_13 = signif(w_if13$p.value,2)
signifind = which(signif_13<.05,arr.ind=T)
emphasize.strong.cells(signifind)
pandoc.table(signif_13)
```

Pairwise Wilcoxon p-values for IF 2014:
```{r wilcoxon_res_2014,  results='asis'}
signif_14 = signif(w_if14$p.value,2)
signifind = which(signif_14<.05,arr.ind=T)
emphasize.strong.cells(signifind)
pandoc.table(signif_14)
```

# Open Access vs. DSM

The chi-square tests comparing OAM and DSM are not significant, suggesting in this data there is no evidence of an association of open access and DSM.

The proportion of open access journals by "required" vs. "not required" DSM is similar as well.

### Fisher's Exact Test for 6 category DSM vs. OAM

The Fisher's Exact Test for DSM vs. OAM tests for the independence of the categories of DSM and OAM (unordered).

Table of counts for 6 category DSM and two category OAM.
```{r oam_dsm_table}
tab1 = with(jdata,table(oam_fac,dsm))
kable(tab1)
```

Table of proportion with Open Access in each DSM category:
```{r oam_proportion_in_dsm}
tibble("DSM"=dsm_labels,"Proportion Open Access"=round(tab1[2,]/colSums(tab1),2))%>%kable()
```

We can test for the association of DSM and OAM with Fisher's Exact Test. The Test result is below:
```{r oam_dsm_fisher}
fishres = broom::tidy(fisher.test(tab1))
kable(fishres)
```

### Chi-Square test for 2 category DSM vs. OAM

Collapsing the categories into a 2x2 table makes the test hypothesis and result easier to interpret. When we collapse DSM into two categories (required vs. not required) there are more counts in each cell so we do not need to use the Fisher's Exact Test but instead can use a Chi-square test (commonly used for large samples).


The number of journals in each of the 2x2 table categories are below:
```{r oam_dsm2cat}
tab2 = with(jdata,table(oam_fac,dsm2_fac))
kable(tab2)
```

Table of proportion with Open Access in each DSM category:
```{r}
jdata%>%group_by(dsm2_fac)%>%summarize("Proprtion Open Access"=mean(oam))%>%
  rename("DSM"=dsm2_fac)%>%kable(digits=3)
```

Table of proportion data sharing required in each Open Access category:
```{r}
jdata%>%group_by(oam_fac)%>%summarize("Proprtion DSM Required"=mean(dsm2))%>%
  rename("OAM"=oam_fac)%>%kable(digits=3)
```

The Chi-square test result is below. Since the chi-square test is not significant, and the proportion of open access journals that is similar for "required" vs. "non-required" journals, it seems that open access is not associated with data sharing requirements.

The chi-square test is testing the hypothesis that Open Access status is associated with data sharing requirement. The test is not significant which suggests that journals with data sharing requirements are not any more likely to be open access than journals without data sharing requirement. Also, open access journals are not more likely to have data sharing requirements than subscription journals.

```{r oam_dsm2fac_chisq}
chires = broom::tidy(chisq.test(tab2))%>%rename(df=parameter)
kable(chires,digits=3)
```

# Publishing Volume

## All Journals

Here we determine how data sharing and open access are related once incorporating publishing volume. In this case, we are considering the "citable item" as the unit of measurement as opposed to journal. In other words, we ask, if we are given a citable item that is open access, is it more likely to have data sharing requirements than a citable item that is subscription based?

### Summary of Number of Citable Items by DSM and OAM

In 2013, the total number of citable items in the set of studied journals was `r jdata_long%>%filter(year==2013)%>%select(citable_items)%>%sum` and in 2014 it was
`r jdata_long%>%filter(year==2014)%>%select(citable_items)%>%na.omit%>%sum`

Summary of citable items in 2013/2014:
```{r citable_volume}
jdata_long%>%group_by(year)%>%
  summarize_at(vars(citable_items),
               funs("sum","mean","median","min","max"),na.rm=T)%>%
  rename("total"=sum)%>%kable(caption="Citable Items by Year")

tmp = jdata_long%>%group_by(year,dsm)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))%>%
  rename(DSM=dsm)
kable(tmp,caption="Citable Items by DSM")

tmp = jdata_long%>%group_by(year,dsm2_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))%>%
  rename(DSM=dsm2_fac)
kable(tmp,caption="Citable Items by Required/Not Required DSM")

tmp = jdata_long%>%group_by(year,oam_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))%>%
  rename(OAM=oam_fac)
kable(tmp,caption="Citable Items by Open Access")
```

Summary with proportions:

```{r}
tmp = jdata_long%>%group_by(year,dsm)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T),
            "Proportion Citable Items Open Access"=
              sum(citable_items[oam==1],na.rm=T)/sum(citable_items,na.rm=T))%>%
  rename(DSM=dsm)
kable(tmp,digits=3)

tmp = jdata_long%>%group_by(year,dsm2_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T),
            "Proportion Citable Items Open Access"=
              sum(citable_items[oam==1],na.rm=T)/sum(citable_items,na.rm=T))%>%
  rename(DSM=dsm2_fac)
kable(tmp,digits=3)


tmp = jdata_long%>%group_by(year,oam_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T),
            "Proportion Citable Items Required DSM"=
              sum(citable_items[dsm2==1],na.rm=T)/sum(citable_items,na.rm=T))%>%
  rename(OAM=oam_fac)
kable(tmp,digits=3)
```

### Chi-square analysis - Citable Item

When we weight the number of open access journals and required data sharing journals by total citable items within each category there is a significant association between open access and data sharing requirement at the citable item level. That is, a citable item that is open access is much more likely to also have a data sharing requirement. This is mainly due to the fact that although the number of journals who have these open access or data sharing requirements is smaller than the number of journals that do not, the total citable articles within those journals is much larger. The p-values for the chi-square test at the citable item level are <2e-16, very significant.

```{r chisq_totalcitable,include=FALSE}
tmp = jdata_long%>%group_by(year,oam_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))
kable(tmp)

tmp = jdata_long%>%group_by(year,dsm2_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))
kable(tmp)

tmp = jdata_long%>%group_by(year,dsm2_fac,oam_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))
kable(tmp)
```

Chi-squre test results: 
```{r chisq_volume}
tmpm = data.frame(matrix(tmp$`Total Citable`[1:4],ncol=2))
colnames(tmpm) = levels(jdata$dsm2_fac)
rownames(tmpm) = levels(jdata$oam_fac)
kable(tmpm,caption="Citable Items by OAM and DSM, 2013")
tmpb = broom::tidy(chisq.test(tmpm))
if(tmpb$p.value < 2e-16) tmpb$p.value = "< 2e-16"
kable(tmpb)

tmpm = data.frame(matrix(tmp$`Total Citable`[1:4+4],ncol=2))
colnames(tmpm) = levels(jdata$dsm2_fac)
rownames(tmpm) = levels(jdata$oam_fac)
kable(tmpm,caption="Citable Items by OAM and DSM, 2014")
tmpb = broom::tidy(chisq.test(tmpm))
if(tmpb$p.value < 2e-16) tmpb$p.value = "< 2e-16"
kable(tmpb)
```


## Remove PLoS One

PLoS One may be skewing the results since it has such high volume, so we try the above analysis after removing this journal.

```{r remove_plosone}
jdata_long0 =  jdata_long # keep old jdata_long object
jdata_long = jdata_long%>%filter(!Journal=="PLoS One")
```

### Summary of Number of Citable Items by DSM and OAM

In 2013, the total number of citable items in the set of studied journals (removing Plos One) was `r jdata_long%>%filter(year==2013)%>%select(citable_items)%>%sum` and in 2014 it was
`r jdata_long%>%filter(year==2014)%>%select(citable_items)%>%na.omit%>%sum`

Summary of citable items in 2013/2014:
```{r citable_volume2}
jdata_long%>%group_by(year)%>%
  summarize_at(vars(citable_items),
               funs("sum","mean","median","min","max"),na.rm=T)%>%
  rename("total"=sum)%>%kable(caption="Citable Items by Year")

tmp = jdata_long%>%group_by(year,dsm)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))%>%
  rename(DSM=dsm)
kable(tmp,caption="Citable Items by DSM")

tmp = jdata_long%>%group_by(year,dsm2_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))%>%
  rename(DSM=dsm2_fac)
kable(tmp,caption="Citable Items by Required/Not Required DSM")

tmp = jdata_long%>%group_by(year,oam_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))%>%
  rename(OAM=oam_fac)
kable(tmp,caption="Citable Items by Open Access")
```

Summary with proportions:
```{r}
tmp = jdata_long%>%group_by(year,dsm)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T),
            "Proportion Citable Items Open Access"=
              sum(citable_items[oam==1],na.rm=T)/sum(citable_items,na.rm=T))%>%
  rename(DSM=dsm)
kable(tmp,digits=3)

tmp = jdata_long%>%group_by(year,dsm2_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T),
            "Proportion Citable Items Open Access"=
              sum(citable_items[oam==1],na.rm=T)/sum(citable_items,na.rm=T))%>%
  rename(DSM=dsm2_fac)
kable(tmp,digits=3)


tmp = jdata_long%>%group_by(year,oam_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T),
            "Proportion Citable Items Required DSM"=
              sum(citable_items[dsm2==1],na.rm=T)/sum(citable_items,na.rm=T))%>%
  rename(OAM=oam_fac)
kable(tmp,digits=3)
```

### Chi-square analysis - Citable Item

The results are still highly significant, likely due to the large number of citable items, but an open access article is still more likely to have been published under data sharing requirements than a subscription article. In 2014, `r signif(tmp[4,5],3)*100`% of open access articles had data sharing requirements as opposed to `r signif(tmp[3,5],3)*100`% for subscription articles. In 2013 it was slightly less different at `r signif(tmp[4,5],3)*100`% vs. `r signif(tmp[3,5],3)*100`%.

```{r chisq_totalcitable2}
tmp = jdata_long%>%group_by(year,oam_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))
kable(tmp)

tmp = jdata_long%>%group_by(year,dsm2_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))
kable(tmp)

tmp = jdata_long%>%group_by(year,dsm2_fac,oam_fac)%>%
  summarize("Num Journals"=n(),"Total Citable"=sum(citable_items,na.rm=T))
kable(tmp)
```

Chi-squre test results: 
```{r chisq_volume2}
tmpm = data.frame(matrix(tmp$`Total Citable`[1:4],ncol=2))
colnames(tmpm) = levels(jdata$dsm2_fac)
rownames(tmpm) = levels(jdata$oam_fac)
kable(tmpm,caption="Citable Items by OAM and DSM, 2013")
tmpb = broom::tidy(chisq.test(tmpm))
if(tmpb$p.value < 2e-16) tmpb$p.value = "< 2e-16"
kable(tmpb)

tmpm = data.frame(matrix(tmp$`Total Citable`[1:4+4],ncol=2))
colnames(tmpm) = levels(jdata$dsm2_fac)
rownames(tmpm) = levels(jdata$oam_fac)
kable(tmpm,caption="Citable Items by OAM and DSM, 2014")
tmpb = broom::tidy(chisq.test(tmpm))
if(tmpb$p.value < 2e-16) tmpb$p.value = "< 2e-16"
kable(tmpb)
```


# Session Info

This analysis was performed in R/Rstudio using knitr with the following session:

```{r sessioninfo}
devtools::session_info()
```
